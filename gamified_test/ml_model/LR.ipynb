{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----> First 5 rows of the training set:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Nativelang</th>\n",
       "      <th>Otherlang</th>\n",
       "      <th>Age</th>\n",
       "      <th>Clicks1</th>\n",
       "      <th>Hits1</th>\n",
       "      <th>Misses1</th>\n",
       "      <th>Score1</th>\n",
       "      <th>Accuracy1</th>\n",
       "      <th>Missrate1</th>\n",
       "      <th>...</th>\n",
       "      <th>Score31</th>\n",
       "      <th>Accuracy31</th>\n",
       "      <th>Missrate31</th>\n",
       "      <th>Clicks32</th>\n",
       "      <th>Hits32</th>\n",
       "      <th>Misses32</th>\n",
       "      <th>Score32</th>\n",
       "      <th>Accuracy32</th>\n",
       "      <th>Missrate32</th>\n",
       "      <th>Dyslexia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender Nativelang Otherlang  Age  Clicks1  Hits1  Misses1  Score1   \n",
       "0    Male         No       Yes    7       10     10        0      10  \\\n",
       "1  Female        Yes       Yes   13       12     12        0      12   \n",
       "2  Female         No       Yes    7        6      6        0       6   \n",
       "3  Female         No       Yes    7        0      0        0       0   \n",
       "4  Female         No       Yes    8        4      4        0       4   \n",
       "\n",
       "   Accuracy1  Missrate1  ...  Score31  Accuracy31  Missrate31  Clicks32   \n",
       "0        1.0        0.0  ...        0    0.000000        0.00        17  \\\n",
       "1        1.0        0.0  ...        4    0.114286        0.00        26   \n",
       "2        1.0        0.0  ...        4    0.114286        0.00        26   \n",
       "3        0.0        0.0  ...        0    0.000000        0.00         1   \n",
       "4        1.0        0.0  ...        1   25.000000        0.05        26   \n",
       "\n",
       "   Hits32  Misses32  Score32  Accuracy32  Missrate32  Dyslexia  \n",
       "0       2         0        2    0.117647    0.000000        No  \n",
       "1       2         2        2    0.076923    0.076923       Yes  \n",
       "2       1         3        1    0.038462    0.115385        No  \n",
       "3       0         0        0    0.000000    0.000000        No  \n",
       "4       2         2        2    0.076923    0.076923        No  \n",
       "\n",
       "[5 rows x 197 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training set\n",
    "df = pd.read_csv(r'.\\gamified_dataset/Dyt-desktop.csv')\n",
    "\n",
    "print(\"#-----> First 5 rows of the training set:\\n\")\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\apps n shit\\programming\\Python\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['Gender'] = label_encoder.fit_transform(df['Gender'])\n",
    "df['Otherlang'] = label_encoder.fit_transform(df['Otherlang'])\n",
    "df['Nativelang'] = label_encoder.fit_transform(df['Nativelang'])\n",
    "df['Dyslexia'] = label_encoder.fit_transform(df['Dyslexia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = df.drop(['Dyslexia'], axis=1)\n",
    "y_labels= df['Dyslexia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_labels, test_size=0.2, random_state=42, stratify=y_labels)\n",
    "\n",
    "# Standardize the input features (optional but recommended)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps n shit\\programming\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.200, Recall: 0.7436\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.82      0.89       651\n",
      "           1       0.33      0.74      0.46        78\n",
      "\n",
      "    accuracy                           0.81       729\n",
      "   macro avg       0.65      0.78      0.67       729\n",
      "weighted avg       0.90      0.81      0.84       729\n",
      "\n",
      "Threshold: 0.205, Recall: 0.7436\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.82      0.89       651\n",
      "           1       0.34      0.74      0.46        78\n",
      "\n",
      "    accuracy                           0.81       729\n",
      "   macro avg       0.65      0.78      0.68       729\n",
      "weighted avg       0.90      0.81      0.84       729\n",
      "\n",
      "Threshold: 0.210, Recall: 0.7436\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.83      0.89       651\n",
      "           1       0.34      0.74      0.47        78\n",
      "\n",
      "    accuracy                           0.82       729\n",
      "   macro avg       0.65      0.79      0.68       729\n",
      "weighted avg       0.90      0.82      0.85       729\n",
      "\n",
      "Threshold: 0.215, Recall: 0.7179\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.83      0.89       651\n",
      "           1       0.34      0.72      0.46        78\n",
      "\n",
      "    accuracy                           0.82       729\n",
      "   macro avg       0.65      0.77      0.67       729\n",
      "weighted avg       0.89      0.82      0.84       729\n",
      "\n",
      "Threshold: 0.220, Recall: 0.7179\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.83      0.89       651\n",
      "           1       0.34      0.72      0.46        78\n",
      "\n",
      "    accuracy                           0.82       729\n",
      "   macro avg       0.65      0.78      0.68       729\n",
      "weighted avg       0.89      0.82      0.85       729\n",
      "\n",
      "Threshold: 0.225, Recall: 0.7179\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.84      0.89       651\n",
      "           1       0.35      0.72      0.47        78\n",
      "\n",
      "    accuracy                           0.82       729\n",
      "   macro avg       0.65      0.78      0.68       729\n",
      "weighted avg       0.90      0.82      0.85       729\n",
      "\n",
      "Threshold: 0.230, Recall: 0.7051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.84      0.89       651\n",
      "           1       0.34      0.71      0.46        78\n",
      "\n",
      "    accuracy                           0.82       729\n",
      "   macro avg       0.65      0.77      0.68       729\n",
      "weighted avg       0.89      0.82      0.85       729\n",
      "\n",
      "Threshold: 0.235, Recall: 0.7051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.84      0.90       651\n",
      "           1       0.35      0.71      0.46        78\n",
      "\n",
      "    accuracy                           0.83       729\n",
      "   macro avg       0.65      0.77      0.68       729\n",
      "weighted avg       0.89      0.83      0.85       729\n",
      "\n",
      "Threshold: 0.240, Recall: 0.7051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.84      0.90       651\n",
      "           1       0.35      0.71      0.46        78\n",
      "\n",
      "    accuracy                           0.83       729\n",
      "   macro avg       0.65      0.77      0.68       729\n",
      "weighted avg       0.89      0.83      0.85       729\n",
      "\n",
      "Threshold: 0.245, Recall: 0.7051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.84      0.90       651\n",
      "           1       0.35      0.71      0.47        78\n",
      "\n",
      "    accuracy                           0.83       729\n",
      "   macro avg       0.66      0.77      0.68       729\n",
      "weighted avg       0.89      0.83      0.85       729\n",
      "\n",
      "Threshold: 0.250, Recall: 0.7051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.90       651\n",
      "           1       0.36      0.71      0.48        78\n",
      "\n",
      "    accuracy                           0.83       729\n",
      "   macro avg       0.66      0.78      0.69       729\n",
      "weighted avg       0.90      0.83      0.86       729\n",
      "\n",
      "Threshold: 0.255, Recall: 0.7051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.90       651\n",
      "           1       0.36      0.71      0.48        78\n",
      "\n",
      "    accuracy                           0.84       729\n",
      "   macro avg       0.66      0.78      0.69       729\n",
      "weighted avg       0.90      0.84      0.86       729\n",
      "\n",
      "Threshold: 0.260, Recall: 0.7051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.90       651\n",
      "           1       0.37      0.71      0.48        78\n",
      "\n",
      "    accuracy                           0.84       729\n",
      "   macro avg       0.66      0.78      0.69       729\n",
      "weighted avg       0.90      0.84      0.86       729\n",
      "\n",
      "Threshold: 0.265, Recall: 0.7051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91       651\n",
      "           1       0.37      0.71      0.49        78\n",
      "\n",
      "    accuracy                           0.84       729\n",
      "   macro avg       0.67      0.78      0.70       729\n",
      "weighted avg       0.90      0.84      0.86       729\n",
      "\n",
      "Threshold: 0.270, Recall: 0.7051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91       651\n",
      "           1       0.38      0.71      0.49        78\n",
      "\n",
      "    accuracy                           0.84       729\n",
      "   macro avg       0.67      0.78      0.70       729\n",
      "weighted avg       0.90      0.84      0.86       729\n",
      "\n",
      "Threshold: 0.275, Recall: 0.7051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91       651\n",
      "           1       0.38      0.71      0.50        78\n",
      "\n",
      "    accuracy                           0.85       729\n",
      "   macro avg       0.67      0.78      0.70       729\n",
      "weighted avg       0.90      0.85      0.87       729\n",
      "\n",
      "Threshold: 0.280, Recall: 0.7051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91       651\n",
      "           1       0.39      0.71      0.50        78\n",
      "\n",
      "    accuracy                           0.85       729\n",
      "   macro avg       0.67      0.79      0.71       729\n",
      "weighted avg       0.90      0.85      0.87       729\n",
      "\n",
      "Threshold: 0.285, Recall: 0.7051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91       651\n",
      "           1       0.39      0.71      0.50        78\n",
      "\n",
      "    accuracy                           0.85       729\n",
      "   macro avg       0.68      0.79      0.71       729\n",
      "weighted avg       0.90      0.85      0.87       729\n",
      "\n",
      "Threshold: 0.290, Recall: 0.6923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92       651\n",
      "           1       0.40      0.69      0.51        78\n",
      "\n",
      "    accuracy                           0.86       729\n",
      "   macro avg       0.68      0.78      0.71       729\n",
      "weighted avg       0.90      0.86      0.87       729\n",
      "\n",
      "Threshold: 0.295, Recall: 0.6923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92       651\n",
      "           1       0.40      0.69      0.51        78\n",
      "\n",
      "    accuracy                           0.86       729\n",
      "   macro avg       0.68      0.78      0.71       729\n",
      "weighted avg       0.90      0.86      0.87       729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score,classification_report\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = {0: 1, 1: 2}  # Adjust the weight for dyslexia class (1) according to your preference\n",
    "\n",
    "model = LogisticRegression(class_weight=class_weights)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Cross-validate the model with different decision thresholds\n",
    "thresholds = np.arange(0.2, 0.3, 0.005)\n",
    "for threshold in thresholds:\n",
    "    # Predict probabilities\n",
    "    y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Apply threshold to get binary predictions\n",
    "    y_pred = (y_pred_prob > threshold).astype(int)\n",
    "    \n",
    "    # Evaluate recall on the test set with the current threshold\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "    # Print the current threshold and recall\n",
    "    print(f\"Threshold: {threshold:.3f}, Recall: {recall:.4f}\")\n",
    "    classification_rep_test = classification_report(y_test, y_pred)\n",
    "    print(classification_rep_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.265, Recall: 0.7051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91       651\n",
      "           1       0.37      0.71      0.49        78\n",
      "\n",
      "    accuracy                           0.84       729\n",
      "   macro avg       0.67      0.78      0.70       729\n",
      "weighted avg       0.90      0.84      0.86       729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Select the final threshold and retrain the model if needed\n",
    "threshold = 0.265\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "y_pred = (y_pred_prob > threshold).astype(int)\n",
    "\n",
    "# Evaluate recall on the test set with the current threshold\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Print the current threshold and recall\n",
    "print(f\"Threshold: {threshold:.3f}, Recall: {recall:.4f}\")\n",
    "classification_rep_test = classification_report(y_test, y_pred)\n",
    "print(classification_rep_test)\n",
    "\n",
    "# Save the model to a .sav file\n",
    "filename = 'lr_model.sav'\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "pickle.dump(scaler, open(\"scaler.sav\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
