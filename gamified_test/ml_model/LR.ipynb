{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----> First 5 rows of the training set:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Nativelang</th>\n",
       "      <th>Otherlang</th>\n",
       "      <th>Age</th>\n",
       "      <th>Clicks1</th>\n",
       "      <th>Hits1</th>\n",
       "      <th>Misses1</th>\n",
       "      <th>Score1</th>\n",
       "      <th>Accuracy1</th>\n",
       "      <th>Missrate1</th>\n",
       "      <th>...</th>\n",
       "      <th>Score31</th>\n",
       "      <th>Accuracy31</th>\n",
       "      <th>Missrate31</th>\n",
       "      <th>Clicks32</th>\n",
       "      <th>Hits32</th>\n",
       "      <th>Misses32</th>\n",
       "      <th>Score32</th>\n",
       "      <th>Accuracy32</th>\n",
       "      <th>Missrate32</th>\n",
       "      <th>Dyslexia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender Nativelang Otherlang  Age  Clicks1  Hits1  Misses1  Score1   \n",
       "0    Male         No       Yes    7       10     10        0      10  \\\n",
       "1  Female        Yes       Yes   13       12     12        0      12   \n",
       "2  Female         No       Yes    7        6      6        0       6   \n",
       "3  Female         No       Yes    7        0      0        0       0   \n",
       "4  Female         No       Yes    8        4      4        0       4   \n",
       "\n",
       "   Accuracy1  Missrate1  ...  Score31  Accuracy31  Missrate31  Clicks32   \n",
       "0        1.0        0.0  ...        0    0.000000        0.00        17  \\\n",
       "1        1.0        0.0  ...        4    0.114286        0.00        26   \n",
       "2        1.0        0.0  ...        4    0.114286        0.00        26   \n",
       "3        0.0        0.0  ...        0    0.000000        0.00         1   \n",
       "4        1.0        0.0  ...        1   25.000000        0.05        26   \n",
       "\n",
       "   Hits32  Misses32  Score32  Accuracy32  Missrate32  Dyslexia  \n",
       "0       2         0        2    0.117647    0.000000        No  \n",
       "1       2         2        2    0.076923    0.076923       Yes  \n",
       "2       1         3        1    0.038462    0.115385        No  \n",
       "3       0         0        0    0.000000    0.000000        No  \n",
       "4       2         2        2    0.076923    0.076923        No  \n",
       "\n",
       "[5 rows x 197 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training set\n",
    "df = pd.read_csv(r'.\\gamified_dataset/Dyt-desktop.csv')\n",
    "\n",
    "print(\"#-----> First 5 rows of the training set:\\n\")\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['Gender'] = label_encoder.fit_transform(df['Gender'])\n",
    "df['Otherlang'] = label_encoder.fit_transform(df['Otherlang'])\n",
    "df['Nativelang'] = label_encoder.fit_transform(df['Nativelang'])\n",
    "df['Dyslexia'] = label_encoder.fit_transform(df['Dyslexia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = df.drop(['Dyslexia'], axis=1)\n",
    "y_labels= df['Dyslexia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_labels, test_size=0.2, random_state=42, stratify=y_labels)\n",
    "\n",
    "# Standardize the input features (optional but recommended)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Haneen\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.200, Recall: 0.7436\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.82      0.89       651\n",
      "           1       0.33      0.74      0.46        78\n",
      "\n",
      "    accuracy                           0.81       729\n",
      "   macro avg       0.65      0.78      0.67       729\n",
      "weighted avg       0.90      0.81      0.84       729\n",
      "\n",
      "Threshold: 0.205, Recall: 0.7436\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.82      0.89       651\n",
      "           1       0.34      0.74      0.46        78\n",
      "\n",
      "    accuracy                           0.81       729\n",
      "   macro avg       0.65      0.78      0.68       729\n",
      "weighted avg       0.90      0.81      0.84       729\n",
      "\n",
      "Threshold: 0.210, Recall: 0.7436\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.83      0.89       651\n",
      "           1       0.34      0.74      0.47        78\n",
      "\n",
      "    accuracy                           0.82       729\n",
      "   macro avg       0.65      0.79      0.68       729\n",
      "weighted avg       0.90      0.82      0.85       729\n",
      "\n",
      "Threshold: 0.215, Recall: 0.7179\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.83      0.89       651\n",
      "           1       0.34      0.72      0.46        78\n",
      "\n",
      "    accuracy                           0.82       729\n",
      "   macro avg       0.65      0.77      0.67       729\n",
      "weighted avg       0.89      0.82      0.84       729\n",
      "\n",
      "Threshold: 0.220, Recall: 0.7179\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.83      0.89       651\n",
      "           1       0.34      0.72      0.46        78\n",
      "\n",
      "    accuracy                           0.82       729\n",
      "   macro avg       0.65      0.78      0.68       729\n",
      "weighted avg       0.89      0.82      0.85       729\n",
      "\n",
      "Threshold: 0.225, Recall: 0.7179\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.84      0.89       651\n",
      "           1       0.35      0.72      0.47        78\n",
      "\n",
      "    accuracy                           0.82       729\n",
      "   macro avg       0.65      0.78      0.68       729\n",
      "weighted avg       0.90      0.82      0.85       729\n",
      "\n",
      "Threshold: 0.230, Recall: 0.7051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.84      0.89       651\n",
      "           1       0.34      0.71      0.46        78\n",
      "\n",
      "    accuracy                           0.82       729\n",
      "   macro avg       0.65      0.77      0.68       729\n",
      "weighted avg       0.89      0.82      0.85       729\n",
      "\n",
      "Threshold: 0.235, Recall: 0.7051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.84      0.90       651\n",
      "           1       0.35      0.71      0.46        78\n",
      "\n",
      "    accuracy                           0.83       729\n",
      "   macro avg       0.65      0.77      0.68       729\n",
      "weighted avg       0.89      0.83      0.85       729\n",
      "\n",
      "Threshold: 0.240, Recall: 0.7051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.84      0.90       651\n",
      "           1       0.35      0.71      0.46        78\n",
      "\n",
      "    accuracy                           0.83       729\n",
      "   macro avg       0.65      0.77      0.68       729\n",
      "weighted avg       0.89      0.83      0.85       729\n",
      "\n",
      "Threshold: 0.245, Recall: 0.7051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.84      0.90       651\n",
      "           1       0.35      0.71      0.47        78\n",
      "\n",
      "    accuracy                           0.83       729\n",
      "   macro avg       0.66      0.77      0.68       729\n",
      "weighted avg       0.89      0.83      0.85       729\n",
      "\n",
      "Threshold: 0.250, Recall: 0.7051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.90       651\n",
      "           1       0.36      0.71      0.48        78\n",
      "\n",
      "    accuracy                           0.83       729\n",
      "   macro avg       0.66      0.78      0.69       729\n",
      "weighted avg       0.90      0.83      0.86       729\n",
      "\n",
      "Threshold: 0.255, Recall: 0.7051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.90       651\n",
      "           1       0.36      0.71      0.48        78\n",
      "\n",
      "    accuracy                           0.84       729\n",
      "   macro avg       0.66      0.78      0.69       729\n",
      "weighted avg       0.90      0.84      0.86       729\n",
      "\n",
      "Threshold: 0.260, Recall: 0.7051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.90       651\n",
      "           1       0.37      0.71      0.48        78\n",
      "\n",
      "    accuracy                           0.84       729\n",
      "   macro avg       0.66      0.78      0.69       729\n",
      "weighted avg       0.90      0.84      0.86       729\n",
      "\n",
      "Threshold: 0.265, Recall: 0.7051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91       651\n",
      "           1       0.37      0.71      0.49        78\n",
      "\n",
      "    accuracy                           0.84       729\n",
      "   macro avg       0.67      0.78      0.70       729\n",
      "weighted avg       0.90      0.84      0.86       729\n",
      "\n",
      "Threshold: 0.270, Recall: 0.7051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91       651\n",
      "           1       0.38      0.71      0.49        78\n",
      "\n",
      "    accuracy                           0.84       729\n",
      "   macro avg       0.67      0.78      0.70       729\n",
      "weighted avg       0.90      0.84      0.86       729\n",
      "\n",
      "Threshold: 0.275, Recall: 0.7051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91       651\n",
      "           1       0.38      0.71      0.50        78\n",
      "\n",
      "    accuracy                           0.85       729\n",
      "   macro avg       0.67      0.78      0.70       729\n",
      "weighted avg       0.90      0.85      0.87       729\n",
      "\n",
      "Threshold: 0.280, Recall: 0.7051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91       651\n",
      "           1       0.39      0.71      0.50        78\n",
      "\n",
      "    accuracy                           0.85       729\n",
      "   macro avg       0.67      0.79      0.71       729\n",
      "weighted avg       0.90      0.85      0.87       729\n",
      "\n",
      "Threshold: 0.285, Recall: 0.7051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91       651\n",
      "           1       0.39      0.71      0.50        78\n",
      "\n",
      "    accuracy                           0.85       729\n",
      "   macro avg       0.68      0.79      0.71       729\n",
      "weighted avg       0.90      0.85      0.87       729\n",
      "\n",
      "Threshold: 0.290, Recall: 0.6923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92       651\n",
      "           1       0.40      0.69      0.51        78\n",
      "\n",
      "    accuracy                           0.86       729\n",
      "   macro avg       0.68      0.78      0.71       729\n",
      "weighted avg       0.90      0.86      0.87       729\n",
      "\n",
      "Threshold: 0.295, Recall: 0.6923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92       651\n",
      "           1       0.40      0.69      0.51        78\n",
      "\n",
      "    accuracy                           0.86       729\n",
      "   macro avg       0.68      0.78      0.71       729\n",
      "weighted avg       0.90      0.86      0.87       729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score,classification_report\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = {0: 1, 1: 2}  # Adjust the weight for dyslexia class (1) according to your preference\n",
    "\n",
    "model = LogisticRegression(class_weight=class_weights)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Cross-validate the model with different decision thresholds\n",
    "thresholds = np.arange(0.2, 0.3, 0.005)\n",
    "for threshold in thresholds:\n",
    "    # Predict probabilities\n",
    "    y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Apply threshold to get binary predictions\n",
    "    y_pred = (y_pred_prob > threshold).astype(int)\n",
    "    \n",
    "    # Evaluate recall on the test set with the current threshold\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "    # Print the current threshold and recall\n",
    "    print(f\"Threshold: {threshold:.3f}, Recall: {recall:.4f}\")\n",
    "    classification_rep_test = classification_report(y_test, y_pred)\n",
    "    print(classification_rep_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.275, Recall: 0.7051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91       651\n",
      "           1       0.38      0.71      0.50        78\n",
      "\n",
      "    accuracy                           0.85       729\n",
      "   macro avg       0.67      0.78      0.70       729\n",
      "weighted avg       0.90      0.85      0.87       729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Select the final threshold and retrain the model if needed\n",
    "threshold = 0.275\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "y_pred = (y_pred_prob > threshold).astype(int)\n",
    "\n",
    "# Evaluate recall on the test set with the current threshold\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Print the current threshold and recall\n",
    "print(f\"Threshold: {threshold:.3f}, Recall: {recall:.4f}\")\n",
    "classification_rep_test = classification_report(y_test, y_pred)\n",
    "print(classification_rep_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\Haneen\\\\AppData\\\\Roaming\\\\Python\\\\Python310\\\\site-packages\\\\~umpy\\\\.libs\\\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.16.1-cp310-cp310-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.16.1 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.16.1-cp310-cp310-win_amd64.whl (376.9 MB)\n",
      "     ------------------------------------ 376.9/376.9 MB 857.0 kB/s eta 0:00:00\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "     -------------------------------------- 133.7/133.7 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting h5py>=3.10.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading h5py-3.11.0-cp310-cp310-win_amd64.whl (3.0 MB)\n",
      "     ---------------------------------------- 3.0/3.0 MB 1.2 MB/s eta 0:00:00\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "     -------------------------------------- 26.4/26.4 MB 836.9 kB/s eta 0:00:00\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading ml_dtypes-0.3.2-cp310-cp310-win_amd64.whl (127 kB)\n",
      "     -------------------------------------- 127.8/127.8 kB 1.3 MB/s eta 0:00:00\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\haneen\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (21.3)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading protobuf-4.25.3-cp310-abi3-win_amd64.whl (413 kB)\n",
      "     -------------------------------------- 413.4/413.4 kB 1.5 MB/s eta 0:00:00\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "     ---------------------------------------- 64.9/64.9 kB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\users\\haneen\\.conda\\envs\\adventure-drivers-main\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (66.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\haneen\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting typing-extensions>=3.6.6 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading wrapt-1.16.0-cp310-cp310-win_amd64.whl (37 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading grpcio-1.64.1-cp310-cp310-win_amd64.whl (4.1 MB)\n",
      "     ---------------------------------------- 4.1/4.1 MB 1.0 MB/s eta 0:00:00\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "     ---------------------------------------- 5.5/5.5 MB 697.2 kB/s eta 0:00:00\n",
      "Collecting keras>=3.0.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 918.0 kB/s eta 0:00:00\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 699.9 kB/s eta 0:00:00\n",
      "Collecting numpy<2.0.0,>=1.23.5 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "     -------------------------------------- 15.8/15.8 MB 596.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\haneen\\.conda\\envs\\adventure-drivers-main\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.38.4)\n",
      "Collecting rich (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "     ------------------------------------ 240.7/240.7 kB 702.6 kB/s eta 0:00:00\n",
      "Collecting namex (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading optree-0.11.0-cp310-cp310-win_amd64.whl (243 kB)\n",
      "     ------------------------------------ 243.8/243.8 kB 746.1 kB/s eta 0:00:00\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading charset_normalizer-3.3.2-cp310-cp310-win_amd64.whl (100 kB)\n",
      "     ------------------------------------ 100.3/100.3 kB 639.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\haneen\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\haneen\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\haneen\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2022.9.24)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "     ------------------------------------ 105.4/105.4 kB 761.1 kB/s eta 0:00:00\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "     ------------------------------------ 227.3/227.3 kB 815.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\haneen\\appdata\\roaming\\python\\python310\\site-packages (from packaging->tensorflow-intel==2.16.1->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\haneen\\appdata\\roaming\\python\\python310\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\haneen\\appdata\\roaming\\python\\python310\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.13.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, numpy, mdurl, markdown, grpcio, google-pasta, gast, charset-normalizer, astunparse, absl-py, tensorboard, requests, optree, opt-einsum, ml-dtypes, markdown-it-py, h5py, rich, keras, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.22.4\n",
      "    Uninstalling numpy-1.22.4:\n",
      "      Successfully uninstalled numpy-1.22.4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = scaler.fit_transform(X_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Haneen\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight={0: 1, 1: 2})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight={0: 1, 1: 2})</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight={0: 1, 1: 2})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = {0: 1, 1: 2}\n",
    "\n",
    "model = LogisticRegression(class_weight=class_weights)\n",
    "\n",
    "# Train the model on the full dataset\n",
    "model.fit(X_features, y_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model to a .sav file\n",
    "filename = 'lr_model.sav'\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "pickle.dump(scaler, open(\"scaler.sav\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
